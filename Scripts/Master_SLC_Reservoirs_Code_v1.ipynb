{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1517fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%run SLC_Functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d0a0d",
   "metadata": {},
   "source": [
    "## Check out and read in the WL data\n",
    "\n",
    "Home page link - https://uhslc.soest.hawaii.edu/\n",
    "Data Dashboard  - https://uhslc.soest.hawaii.edu/reservoir/\n",
    "\n",
    "####  Reservoir level data from the Sea Level center Reservoir Database gets pulled by Pull_WL_Data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "503e4b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgorb\\OneDrive\\Documents\\GitHub\\SLC_Reservoir_Data\\Scripts\\SLC_Functions.py:30: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(os.path.join(datapath, file), parse_dates=['date'])\n",
      "C:\\Users\\bgorb\\OneDrive\\Documents\\GitHub\\SLC_Reservoir_Data\\Scripts\\SLC_Functions.py:30: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(os.path.join(datapath, file), parse_dates=['date'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>date_min</th>\n",
       "      <th>date_max</th>\n",
       "      <th>mean_WL</th>\n",
       "      <th>median_WL</th>\n",
       "      <th>min_WL</th>\n",
       "      <th>max_WL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDD00214</td>\n",
       "      <td>2018-02-07 20:09:00+00:00</td>\n",
       "      <td>2024-09-27 21:04:00+00:00</td>\n",
       "      <td>1471.264692</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>-129570.0</td>\n",
       "      <td>130758.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDD00CC6</td>\n",
       "      <td>2018-02-07 20:09:00+00:00</td>\n",
       "      <td>2024-09-27 21:04:00+00:00</td>\n",
       "      <td>939.506339</td>\n",
       "      <td>832.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>131071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDD01162</td>\n",
       "      <td>2022-04-26 22:09:00+00:00</td>\n",
       "      <td>2024-09-27 21:04:00+00:00</td>\n",
       "      <td>15293.554955</td>\n",
       "      <td>-226.0</td>\n",
       "      <td>-324.0</td>\n",
       "      <td>131071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EDD024F8</td>\n",
       "      <td>2018-02-07 20:09:00+00:00</td>\n",
       "      <td>2024-09-27 21:04:00+00:00</td>\n",
       "      <td>38210.626583</td>\n",
       "      <td>38142.0</td>\n",
       "      <td>-108451.0</td>\n",
       "      <td>131071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDD02A2A</td>\n",
       "      <td>2018-02-07 20:09:00+00:00</td>\n",
       "      <td>2024-09-27 21:04:00+00:00</td>\n",
       "      <td>96898.021513</td>\n",
       "      <td>97104.0</td>\n",
       "      <td>-74419.0</td>\n",
       "      <td>131071.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id                  date_min                  date_max  \\\n",
       "0   EDD00214 2018-02-07 20:09:00+00:00 2024-09-27 21:04:00+00:00   \n",
       "1   EDD00CC6 2018-02-07 20:09:00+00:00 2024-09-27 21:04:00+00:00   \n",
       "2   EDD01162 2022-04-26 22:09:00+00:00 2024-09-27 21:04:00+00:00   \n",
       "3   EDD024F8 2018-02-07 20:09:00+00:00 2024-09-27 21:04:00+00:00   \n",
       "4   EDD02A2A 2018-02-07 20:09:00+00:00 2024-09-27 21:04:00+00:00   \n",
       "\n",
       "        mean_WL  median_WL    min_WL    max_WL  \n",
       "0   1471.264692     1470.0 -129570.0  130758.0  \n",
       "1    939.506339      832.0     658.0  131071.0  \n",
       "2  15293.554955     -226.0    -324.0  131071.0  \n",
       "3  38210.626583    38142.0 -108451.0  131071.0  \n",
       "4  96898.021513    97104.0  -74419.0  131071.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.join(\"..\", \"Data/WL_Data2024-09-27/UHSLC\")\n",
    "\n",
    "# Create a metadata describe frame for the Reservoir data \n",
    "data_describe = create_metadata_from_SLC_Data(datapath)\n",
    "\n",
    "data_describe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b9941",
   "metadata": {},
   "source": [
    "## Convert to daily Water Level data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3234b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgorb\\OneDrive\\Documents\\GitHub\\SLC_Reservoir_Data\\Scripts\\SLC_Functions.py:75: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, parse_dates=['date'])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:49\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m datapath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/WL_Data2024-09-27/UHSLC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m daily_dic \u001b[38;5;241m=\u001b[39m process_SLC_Data_To_daily(datapath)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\SLC_Reservoir_Data\\Scripts\\SLC_Functions.py:93\u001b[0m, in \u001b[0;36mprocess_SLC_Data_To_daily\u001b[1;34m(directory, std_threshold)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Set the 'date' column as index and resample to daily frequency\u001b[39;00m\n\u001b[0;32m     92\u001b[0m data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 93\u001b[0m data_daily \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Store the resampled daily data in the dictionary\u001b[39;00m\n\u001b[0;32m     96\u001b[0m daily_dic[file] \u001b[38;5;241m=\u001b[39m data_daily\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:1384\u001b[0m, in \u001b[0;36mResampler.mean\u001b[1;34m(self, numeric_only, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m maybe_warn_args_and_kwargs(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, args, kwargs)\n\u001b[0;32m   1383\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_resampler_func(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, args, kwargs)\n\u001b[1;32m-> 1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_downsample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:1782\u001b[0m, in \u001b[0;36mDatetimeIndexResampler._downsample\u001b[1;34m(self, how, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# we are downsampling\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# we want to call the actual grouper method here\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1782\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper)\u001b[38;5;241m.\u001b[39maggregate(how, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;66;03m# test_resample_axis1\u001b[39;00m\n\u001b[0;32m   1785\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper)\u001b[38;5;241m.\u001b[39maggregate(how, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m   1431\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m-> 1432\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:187\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:603\u001b[0m, in \u001b[0;36mApply.apply_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    602\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_str(obj, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:693\u001b[0m, in \u001b[0;36mApply._apply_str\u001b[1;34m(self, obj, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    691\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, func)\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[1;32m--> 693\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# people may aggregate on a non-callable attribute\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "datapath = os.path.join(\"..\", \"Data/WL_Data2024-09-27/UHSLC\")\n",
    "\n",
    "daily_dic = process_SLC_Data_To_daily(datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b75bcf",
   "metadata": {},
   "source": [
    "# Read in the USGS Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52040a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "USGS_directory = os.path.join(\"..\", \"Data/WL_Data2024-09-27/USGS\")\n",
    "daily_dic_USGS = process_USGS_Data_To_daily(USGS_directory)\n",
    "\n",
    "## Get rid of the date part in the keys:\n",
    "daily_dic_USGS = {key.split('--')[0] + '.csv': value for key, value in daily_dic_USGS.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ceac2",
   "metadata": {},
   "source": [
    "##### Merge SLC data and USGS Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c062ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_dic.update(daily_dic_USGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ccd87",
   "metadata": {},
   "source": [
    "## Read In the Precip data from HCDP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897cef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RainData = pd.read_csv(os.path.join(\"..\", 'Data/HCDP_Rainfall_Daily_Data', \"HCDP_RainData2018-2024.csv\"))\n",
    "RainData = RainData.set_index(\"index\")   # make sure the index is date\n",
    "RainData.index = pd.to_datetime(RainData.index, errors='coerce')\n",
    "\n",
    "\n",
    "RainData_Meta = pd.read_csv(os.path.join(\"..\", 'Data/HCDP_Rainfall_Daily_Data', \"HCDP_Rain_METADATA_2018-2024.csv\"))\n",
    "\n",
    "# First make Arc read it as a string \n",
    "RainData_Meta[\"SKN\"] = RainData_Meta[\"SKN\"].astype(str)+\"_R\"  \n",
    "RainData_Meta.to_csv(os.path.join(\"..\", 'Data/HCDP_Rainfall_Daily_Data', \"HCDP_Rain_METADATA_2018-2024_ArcrReady.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67fa6e",
   "metadata": {},
   "source": [
    "## Went into Arc to create the near table\n",
    "- Used RainData_Meta_v2.csv, cleared out useless columns to make RainData_Meta_v2_Clean.csv. \n",
    "- Then manually merged UHSLC_Station_Metadata.csv, and USGS_ID_Meta.xlsx, so they only had the station names and lat lon and IDs. \n",
    "- In Arc brought in, turned to shapefiles, then near table tool on the Reservoirs, selecting only the 10 closest rain station points.  \n",
    "- Arc only records the FIDs so have to do 2 joins on the original tables. \n",
    "- Result is Res_Rain_Near_Table_New_v2.csv, after 30 minutes of wasted time \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e0f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_table = pd.read_csv(os.path.join(\"..\", \"Data/Metadata_Sheets\", \"Res_Rain_Near_Table_New_v2.csv\"))\n",
    "\n",
    "## Import metadata\n",
    "Station_Meta = pd.read_csv(os.path.join(\"..\", \"Data/Metadata_Sheets\", \"ALL_HI_reservoirs_Metadata.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac200fb",
   "metadata": {},
   "source": [
    "# Create plots of reservoir level and rainfall \n",
    "\n",
    "Use this for testing \n",
    "smalldic = {key: daily_dic[key] for key in ['EDD00214.csv', 'EDD00CC6.csv', 'EDD01FB0.csv', 'EDD024F8.csv']}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464de30b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_WL_ommitted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#smalldic = {key: daily_dic[key] for key in ['EDD00214.csv', 'EDD00CC6.csv', 'EDD024F8.csv', 'USGS_213133158014201.csv']}   # For testing \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Paramater that changes how many near rainfall stations to use \u001b[39;00m\n\u001b[0;32m      4\u001b[0m Nearest_X_Stations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m daily_WL_ommitted\u001b[38;5;241m.\u001b[39mkeys():  \u001b[38;5;66;03m#daily_dic.keys(): \u001b[39;00m\n\u001b[0;32m      7\u001b[0m     stat_id \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]   \u001b[38;5;66;03m# Pull off the .csv\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#### Modify for USGS \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily_WL_ommitted' is not defined"
     ]
    }
   ],
   "source": [
    "#smalldic = {key: daily_dic[key] for key in ['EDD00214.csv', 'EDD00CC6.csv', 'EDD024F8.csv', 'USGS_213133158014201.csv']}   # For testing \n",
    "\n",
    "# Paramater that changes how many near rainfall stations to use \n",
    "Nearest_X_Stations = 10\n",
    "\n",
    "for i in daily_dic.keys():  #daily_dic.keys(): \n",
    "    stat_id = i.split('.')[0]   # Pull off the .csv\n",
    "    #### Modify for USGS \n",
    "    isla = Station_Meta['Res_ID'][Station_Meta['id'] == stat_id].values[0].split('-')[0]  # Pull out the island from the dlnr ID\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,3))\n",
    "    daily_dic[i].plot(y='data', ax=ax, marker=\".\", color='k', alpha=0.5, label=\"WL_(ft)\")\n",
    "    \n",
    "    # Add the lever alert lines\n",
    "    Level_alert_on = Station_Meta['level_alert_on'][Station_Meta['id'] == stat_id].values[0]\n",
    "    plt.axhline(y=Level_alert_on, color='r', linestyle='-', alpha = 0.5)   \n",
    "    Level_alert_off = Station_Meta['level_alert_off'][Station_Meta['id'] == stat_id].values[0]\n",
    "    plt.axhline(y=Level_alert_off, color='g', linestyle='-', alpha = 0.5)\n",
    "    \n",
    "    \n",
    "    nearest_SKN_table = near_table[near_table['ID'] == stat_id]     # Reference the nearest stations for rainfall\n",
    "    nearest_X_SKNs =  nearest_SKN_table[nearest_SKN_table['NEAR_RANK'] <= Nearest_X_Stations]  # Cut to the number specified in Nearest_X_Stations\n",
    "    nearest5skns = list(nearest_X_SKNs['SKN'])                      # Pull out the SKN vales from the dataframe \n",
    "    nearest5skns = list(map(lambda x: x.split(\"_\")[0], nearest5skns))  # Quick list function map to pull of the \"_R\" from each SKN\n",
    "    nearest5skns = list(map(lambda x: str(x), nearest5skns))  # Quick list function map to turn values back into str\n",
    "    rain_datatoplot_5 = RainData[nearest5skns]     # make it a single dataframe \n",
    "    rain_datatoplot_5_mean = rain_datatoplot_5.mean(axis=1)    # calculate the average rainfall over all N stations \n",
    "    \n",
    "    # Plot Rain Data\n",
    "    ax2=ax.twinx()\n",
    "    rain_datatoplot_5_mean.plot(ax=ax2, color='b', alpha=0.2)\n",
    "    \n",
    "    plt.title(stat_id +\" \"+ \"{}\".format(Station_Meta['Name'][Station_Meta['id'] == stat_id].values[0])+\"--\"+isla)\n",
    "    ax2.set_ylabel('Rainfall (mm)', color='b')\n",
    "    ax.set_ylabel('WL-reservoir (ft)', color='k')\n",
    "    plt.savefig('res.png')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d7c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0de5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
